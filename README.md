# ğŸ“¦ Fair-Sampler  
*By Geon*

**Adaptive, feedback-controlled sampler that applies negative feedback to keep class distribution fair and stable during AI training.**  
Forces rapid convergence to target ratios â€” while preserving unbiased estimates via **importance weighting**.
// ì‹¤ì „ ë¡±í…Œì¼/ë“œë¦¬í”„íŠ¸ í™˜ê²½ì—ì„œ ìƒ˜í”Œë§ ë¹„ìœ¨ì„ ì‹¤ì‹œê°„ ì œì–´í•˜ê³ , ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ë¡œ í¸í–¥ ì—†ì´ í•™ìŠµ

![Rebalance (99:1 â†’ 50:50)](assets/fair_rebalance.png)
![Driftâ†’Recovery (10 cycles)](assets/drift_recovery.png)

## Install
```bash
pip install -e .
```

## Quick Start
```python
from gfs.controller import FeedbackController
from gfs.batch_sampler import FeedbackBatchSampler
from gfs.iw import importance_weights

controller = FeedbackController(num_classes=K, target_probs=[1/K]*K, alpha=8.0)
sampler = FeedbackBatchSampler(labels, batch_size=256, steps_per_epoch=100, controller=controller)

for batch_indices in sampler:
    y = labels[batch_indices]                        # class ids for the batch
    p = controller.get_probs()                       # current sampling probs
    w = importance_weights(y, controller.q, p)       # unbiased IW (meanâ‰ˆ1)
    loss = (w * criterion(model(x[batch_indices]), torch.as_tensor(y))).mean()
    loss.backward(); optimizer.step(); optimizer.zero_grad()
    controller.step_update(y, losses=None)           # or pass per-sample loss for EWMA(loss)
```

## Core Idea
- **Negative feedback** counteracts imbalance: under-sampled classes get higher sampling probability.
- **Softmax control**: `p_i(t) = softmax(Î± * (Î»1 * deficit_i + Î»2 * ewma_loss_i))`
- **Unbiased training**: `w = q[labels] / p[labels]`, normalized to mean 1.
// pëŠ” ë§¤ step ì ì‘, wëŠ” ê·¸ pì— ì •ë ¬ë˜ì–´ bias 0

## Stability Tips
- Set a **probability floor**: `min_prob=1e-6` (default) to avoid extreme weights.
- If drift is wild: `importance_weights(..., max_w=50.0)`.
- Consider **Î± warm-up/cool-down** for smooth adaptation.
// ì´ˆê¸° ê¸‰ê²© íŠ ë°©ì§€

## Reproducibility
```python
import random, numpy as np, torch
random.seed(42); np.random.seed(42); torch.manual_seed(42)
if torch.cuda.is_available(): torch.cuda.manual_seed_all(42)
```

## Example
See `train_mnist.py` for a runnable demo (replace with CIFAR-LT/medical/streaming as needed).
// ì˜ˆì‹œëŠ” ë°ëª¨ìš©, ì–´ë–¤ ë°ì´í„°ì—ë„ ë°”ë¡œ ì ìš© ê°€ëŠ¥
